{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning with TensorFlow: multiple hidden layers\n",
    "\n",
    "Date: August 21-23, 2018\n",
    "\n",
    "Neural network: three hidden layers\n",
    "\n",
    "Classification of human body motion:\n",
    "- walking\n",
    "- sitting down\n",
    "- turning right while walking\n",
    "- turning left while walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sg\n",
    "import serial\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data set for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NUMS = 260  # per sec\n",
    "SAMPLING_RATE = 80.0  # Hz\n",
    "GYRO_RESOLUTION = 250.0 / 32768.0\n",
    "ACCEL_RESOLUTION = 2.0 / 32768.0\n",
    "SCALING = 32768.0\n",
    "\n",
    "TRAINING_SET = [['./20180821_walking_straight.csv', 0],\n",
    "               ['./20180821_sitting.csv', 1],\n",
    "               ['./20180821_turning_left.csv', 2],\n",
    "               ['./20180821_turning_right.csv', 3],                \n",
    "               ['./20180823_walking_straight.csv', 0],\n",
    "               ['./20180823_sitting.csv', 1],\n",
    "               ['./20180823_turning_left.csv', 2],\n",
    "               ['./20180823_turning_right.csv', 3]]\n",
    "\n",
    "TEST_SET = [['./20180822_walking_straight.csv', 0],\n",
    "            ['./20180822_sitting.csv', 1],\n",
    "            ['./20180822_turning_left.csv', 2],\n",
    "            ['./20180822_turning_right.csv', 3]]\n",
    "\n",
    "TIME_INTERVAL = 260.0 / SAMPLING_RATE  # sec\n",
    "\n",
    "MEASUREMENTS = 8\n",
    "RECORDS = 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gres = lambda v: v * GYRO_RESOLUTION\n",
    "#ares = lambda v: v * ACCEL_RESOLUTION\n",
    "gres = lambda v: v / SCALING\n",
    "ares = lambda v: v / SCALING\n",
    "to_time = lambda v: v / SAMPLING_RATE\n",
    "\n",
    "def conv(df, lpf=False):\n",
    "    df[['gx', 'gy', 'gz']] = df[['gx', 'gy', 'gz']].apply(gres)\n",
    "    df[['ax', 'ay', 'az']] = df[['ax', 'ay', 'az']].apply(ares)\n",
    "    if lpf:\n",
    "        CUTOFF = 10.0\n",
    "        b, a = sg.butter(5, CUTOFF/SAMPLING_RATE, btype='low')\n",
    "        df[['ax', 'ay', 'az']] = df[['ax', 'ay', 'az']].apply(lambda row: sg.lfilter(b, a, row))\n",
    "        CUTOFF = 10.0\n",
    "        b, a = sg.butter(5, CUTOFF/SAMPLING_RATE, btype='low')\n",
    "        df[['gx', 'gy', 'gz']] = df[['gx', 'gy', 'gz']].apply(lambda row: sg.lfilter(b, a, row))\n",
    "    df[['cnt']] = df[['cnt']].apply(to_time)\n",
    "    df.set_index('cnt', drop=True, inplace=True)\n",
    "    # measurements = df.tail(1).iloc[0,0] + 1\n",
    "    # return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "test_set = []\n",
    "\n",
    "def label(l):\n",
    "    ll = [0,0,0,0]\n",
    "    ll[l] = 1\n",
    "    return ll\n",
    "\n",
    "for file, l in TRAINING_SET:\n",
    "    df = pd.read_csv(file, dtype=np.int16)\n",
    "    conv(df, lpf=True)\n",
    "    for i in range(MEASUREMENTS):\n",
    "        training_set.append([df[df['id']==i], label(l)])\n",
    "        \n",
    "for file, l in TEST_SET:\n",
    "    df = pd.read_csv(file, dtype=np.int16)\n",
    "    conv(df, lpf=True)\n",
    "    for i in range(MEASUREMENTS):\n",
    "        test_set.append([df[df['id']==i], label(l)])\n",
    "    \n",
    "random.shuffle(training_set)\n",
    "random.shuffle(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use accel x axis and gyro z axis values for classification of human body motion\n",
    "train_x, train_t = [], []\n",
    "test_x, test_t = [], []\n",
    "for df, label in training_set:\n",
    "    values = np.concatenate((df['ax'].values, df['ay'].values, df['az'].values,\n",
    "                             df['gx'].values, df['gy'].values, df['gz'].values),\n",
    "                            axis=None)\n",
    "    train_x.append(values)\n",
    "    train_t.append(label)\n",
    "for df, label in test_set:\n",
    "    values = np.concatenate((df['ax'].values, df['ay'].values, df['az'].values,\n",
    "                             df['gx'].values, df['gy'].values, df['gz'].values),\n",
    "                            axis=None)\n",
    "    test_x.append(values)\n",
    "    test_t.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiny\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(20180823)\n",
    "tf.set_random_seed(20180823)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = SAMPLE_NUMS * 6\n",
    "num_units1 = 64\n",
    "num_units2 = 64\n",
    "num_classes = 4\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, num_samples])\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal([num_samples, num_units1]))\n",
    "b1 = tf.Variable(tf.zeros([num_units1]))\n",
    "y1 = tf.matmul(x, w1) + b1\n",
    "hidden1 = tf.nn.relu(y1)\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([num_units1, num_units2]))\n",
    "b2 = tf.Variable(tf.zeros([num_units2]))\n",
    "y2 = tf.matmul(hidden1, w2) + b2\n",
    "hidden2 = tf.nn.tanh(y2)\n",
    "\n",
    "w0 = tf.Variable(tf.zeros([num_units2, num_classes]))\n",
    "b0 = tf.Variable(tf.zeros([num_classes]))\n",
    "p = tf.nn.softmax(tf.matmul(hidden2, w0) + b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.placeholder(tf.float32, [None, num_classes])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100, Loss: 39.35624694824219, Accuracy: 0.78125\n",
      "Step: 200, Loss: 32.8271484375, Accuracy: 0.78125\n",
      "Step: 300, Loss: 27.73154067993164, Accuracy: 0.8125\n",
      "Step: 400, Loss: 23.7447509765625, Accuracy: 0.8125\n",
      "Step: 500, Loss: 21.049095153808594, Accuracy: 0.8125\n",
      "Step: 600, Loss: 19.460941314697266, Accuracy: 0.8125\n",
      "Step: 700, Loss: 17.95561981201172, Accuracy: 0.8125\n",
      "Step: 800, Loss: 16.74079132080078, Accuracy: 0.84375\n",
      "Step: 900, Loss: 15.858845710754395, Accuracy: 0.84375\n",
      "Step: 1000, Loss: 14.94544792175293, Accuracy: 0.84375\n",
      "Step: 1100, Loss: 14.040693283081055, Accuracy: 0.84375\n",
      "Step: 1200, Loss: 13.707253456115723, Accuracy: 0.84375\n",
      "Step: 1300, Loss: 13.328290939331055, Accuracy: 0.875\n",
      "Step: 1400, Loss: 12.910215377807617, Accuracy: 0.875\n",
      "Step: 1500, Loss: 12.367615699768066, Accuracy: 0.875\n",
      "Step: 1600, Loss: 12.36126708984375, Accuracy: 0.875\n",
      "Step: 1700, Loss: 12.207801818847656, Accuracy: 0.875\n",
      "Step: 1800, Loss: 11.923361778259277, Accuracy: 0.875\n",
      "Step: 1900, Loss: 11.979299545288086, Accuracy: 0.875\n",
      "Step: 2000, Loss: 12.118168830871582, Accuracy: 0.875\n",
      "Step: 2100, Loss: 12.240107536315918, Accuracy: 0.875\n",
      "Step: 2200, Loss: 12.098617553710938, Accuracy: 0.875\n",
      "Step: 2300, Loss: 12.34245777130127, Accuracy: 0.875\n",
      "Step: 2400, Loss: 12.652978897094727, Accuracy: 0.875\n",
      "Step: 2500, Loss: 12.960702896118164, Accuracy: 0.875\n",
      "Step: 2600, Loss: 13.320647239685059, Accuracy: 0.875\n",
      "Step: 2700, Loss: 13.376749992370605, Accuracy: 0.875\n",
      "Step: 2800, Loss: 13.439885139465332, Accuracy: 0.875\n",
      "Step: 2900, Loss: 13.481854438781738, Accuracy: 0.875\n",
      "Step: 3000, Loss: 13.596081733703613, Accuracy: 0.875\n",
      "Step: 3100, Loss: 13.674482345581055, Accuracy: 0.875\n",
      "Step: 3200, Loss: 13.484013557434082, Accuracy: 0.875\n",
      "Step: 3300, Loss: 13.656085968017578, Accuracy: 0.875\n",
      "Step: 3400, Loss: 13.876049041748047, Accuracy: 0.875\n",
      "Step: 3500, Loss: 14.007536888122559, Accuracy: 0.875\n",
      "Step: 3600, Loss: 14.122010231018066, Accuracy: 0.875\n",
      "Step: 3700, Loss: 14.182174682617188, Accuracy: 0.875\n",
      "Step: 3800, Loss: 14.378789901733398, Accuracy: 0.875\n",
      "Step: 3900, Loss: 14.531028747558594, Accuracy: 0.875\n",
      "Step: 4000, Loss: 14.708057403564453, Accuracy: 0.875\n",
      "Step: 4100, Loss: 14.88204574584961, Accuracy: 0.875\n",
      "Step: 4200, Loss: 15.047871589660645, Accuracy: 0.875\n",
      "Step: 4300, Loss: 15.204852104187012, Accuracy: 0.875\n",
      "Step: 4400, Loss: 15.350743293762207, Accuracy: 0.875\n",
      "Step: 4500, Loss: 15.416875839233398, Accuracy: 0.875\n",
      "Step: 4600, Loss: 15.725332260131836, Accuracy: 0.875\n",
      "Step: 4700, Loss: 15.963873863220215, Accuracy: 0.875\n",
      "Step: 4800, Loss: 15.937813758850098, Accuracy: 0.875\n",
      "Step: 4900, Loss: 15.393966674804688, Accuracy: 0.875\n",
      "Step: 5000, Loss: 15.5656156539917, Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in range(5000):\n",
    "    i += 1\n",
    "    sess.run(train_step, feed_dict={x:train_x, t:train_t})\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val, h1, h2, y1_, y2_ = sess.run([loss, accuracy, hidden1, hidden2, y1, y2], feed_dict={x:test_x, t:test_t})\n",
    "        print('Step: {}, Loss: {}, Accuracy: {}'.format(i, loss_val, acc_val))\n",
    "#        for h in h1:\n",
    "#            print([int(z*100) for z in h])\n",
    "#        for y in y1_:\n",
    "#            print([z for z in y])\n",
    "#        for h in h2:\n",
    "#            print([int(z*100) for z in h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 94,  1,  0],\n",
       "       [ 0,  0,  0, 99],\n",
       "       [16,  1, 81,  0],\n",
       "       [ 0, 98,  0,  0],\n",
       "       [42,  0, 56,  0],\n",
       "       [25,  0, 74,  0],\n",
       "       [ 0,  0,  0, 99],\n",
       "       [ 1,  3,  0, 95],\n",
       "       [ 0, 99,  0,  0],\n",
       "       [ 2, 97,  0,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test = sess.run(p, feed_dict={x:test_x})\n",
    "(p_test*100).astype(int)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 1, 0],\n",
       " [1, 0, 0, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
