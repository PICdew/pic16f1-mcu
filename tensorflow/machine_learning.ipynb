{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sg\n",
    "import serial\n",
    "import time\n",
    "import random\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NUMS = 260  # sec\n",
    "SAMPLING_RATE = 80.0  # Hz\n",
    "GYRO_RESOLUTION = 250.0 / 32768.0\n",
    "ACCEL_RESOLUTION = 2.0 / 32768.0\n",
    "\n",
    "FILE0 = './20180821_walking_straight.csv'\n",
    "FILE1 = './20180821_sitting_down.csv'\n",
    "FILE2 = './20180821_turning_left.csv'\n",
    "#FILE3 = './20180821_turning_right.csv'\n",
    "\n",
    "TIME_INTERVAL = 260.0 / SAMPLING_RATE  # sec\n",
    "\n",
    "MEASUREMENTS = 8\n",
    "RECORDS = 260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data set for training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "gres = lambda v: v * GYRO_RESOLUTION\n",
    "ares = lambda v: v * ACCEL_RESOLUTION\n",
    "to_time = lambda v: v / SAMPLING_RATE\n",
    "\n",
    "def conv(df):\n",
    "    df[['gx', 'gy', 'gz']] = df[['gx', 'gy', 'gz']].apply(gres)\n",
    "    df[['ax', 'ay', 'az']] = df[['ax', 'ay', 'az']].apply(ares)\n",
    "    CUTOFF = 10.0\n",
    "    b, a = sg.butter(5, CUTOFF/SAMPLING_RATE, btype='low')\n",
    "    df[['ax', 'ay', 'az']] = df[['ax', 'ay', 'az']].apply(lambda row: sg.lfilter(b, a, row))\n",
    "    CUTOFF = 10.0\n",
    "    b, a = sg.butter(5, CUTOFF/SAMPLING_RATE, btype='low')\n",
    "    df[['gx', 'gy', 'gz']] = df[['gx', 'gy', 'gz']].apply(lambda row: sg.lfilter(b, a, row))\n",
    "    df[['cnt']] = df[['cnt']].apply(to_time)\n",
    "    df.set_index('cnt', drop=True, inplace=True)\n",
    "    # measurements = df.tail(1).iloc[0,0] + 1\n",
    "    # return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(FILE0, dtype=np.int16)\n",
    "df1 = pd.read_csv(FILE1, dtype=np.int16)\n",
    "df2 = pd.read_csv(FILE2, dtype=np.int16)\n",
    "#df3 = pd.read_csv(FILE3, dtype=np.int16)\n",
    "\n",
    "conv(df0)\n",
    "conv(df1)\n",
    "conv(df2)\n",
    "#conv(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df0['label'] = np.full(RECORDS*MEASUREMENTS, 0)\n",
    "df1['label'] = np.full(RECORDS*MEASUREMENTS, 1)\n",
    "df2['label'] = np.full(RECORDS*MEASUREMENTS, 2)\n",
    "#df3['label'] = np.full(RECORDS*MEASUREMENTS, 2)\n",
    "\n",
    "df_set, df0set, df1set, df2set = [], [], [], []\n",
    "#df_set, df0set, df1set = [], [], []\n",
    "for i in range(MEASUREMENTS):\n",
    "    df0set.append([df0[df0['id'] == i], [1,0,0]])\n",
    "    df1set.append([df1[df1['id'] == i], [0,1,0]])\n",
    "    df2set.append([df2[df2['id'] == i], [0,0,1]])\n",
    "#   df2set.append([df2[df2['id'] == i], [0,0,0,1]])\n",
    "\n",
    "df_set.extend(df0set)\n",
    "df_set.extend(df1set)\n",
    "df_set.extend(df2set)\n",
    "#df_set.extend(df3set)\n",
    "\n",
    "random.shuffle(df_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_t = []\n",
    "for df, label in df_set:\n",
    "    train_x.append(df['az'].values)\n",
    "    train_t.append(label)\n",
    "#train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "np.random.seed(20180821)\n",
    "tf.set_random_seed(20180821)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 16\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 260])\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal([260, num_units]))\n",
    "b1 = tf.Variable(tf.zeros([num_units]))\n",
    "hidden1 = tf.nn.tanh(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w0 = tf.Variable(tf.zeros([num_units, 3]))\n",
    "b0 = tf.Variable(tf.zeros([3]))\n",
    "p = tf.nn.softmax(tf.matmul(hidden1, w0) + b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.placeholder(tf.float32, [None, 3])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100, Loss: 23.68749237060547, Accuracy: 0.75\n",
      "Step: 200, Loss: 20.612253189086914, Accuracy: 0.7083333134651184\n",
      "Step: 300, Loss: 18.428131103515625, Accuracy: 0.75\n",
      "Step: 400, Loss: 16.851245880126953, Accuracy: 0.75\n",
      "Step: 500, Loss: 15.73366928100586, Accuracy: 0.75\n",
      "Step: 600, Loss: 14.938302993774414, Accuracy: 0.75\n",
      "Step: 700, Loss: 14.356730461120605, Accuracy: 0.75\n",
      "Step: 800, Loss: 13.91321849822998, Accuracy: 0.75\n",
      "Step: 900, Loss: 13.560996055603027, Accuracy: 0.75\n",
      "Step: 1000, Loss: 13.270149230957031, Accuracy: 0.75\n",
      "Step: 1100, Loss: 13.019122123718262, Accuracy: 0.75\n",
      "Step: 1200, Loss: 12.79128646850586, Accuracy: 0.75\n",
      "Step: 1300, Loss: 12.561667442321777, Accuracy: 0.75\n",
      "Step: 1400, Loss: 12.314582824707031, Accuracy: 0.75\n",
      "Step: 1500, Loss: 12.083556175231934, Accuracy: 0.75\n",
      "Step: 1600, Loss: 11.867513656616211, Accuracy: 0.75\n",
      "Step: 1700, Loss: 11.668277740478516, Accuracy: 0.75\n",
      "Step: 1800, Loss: 11.373058319091797, Accuracy: 0.75\n",
      "Step: 1900, Loss: 10.5880708694458, Accuracy: 0.8333333134651184\n",
      "Step: 2000, Loss: 9.845556259155273, Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in range(2000):\n",
    "    i += 1\n",
    "    sess.run(train_step, feed_dict={x:train_x, t:train_t})\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={x:train_x, t: train_t})\n",
    "        print('Step: {}, Loss: {}, Accuracy: {}'.format(i, loss_val, acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.93604600e-01, 3.20562394e-04, 6.07495848e-03],\n",
       "       [2.12222859e-01, 1.74142793e-01, 6.13634348e-01],\n",
       "       [1.42434975e-02, 7.00233221e-01, 2.85523236e-01],\n",
       "       [1.72671542e-01, 2.21190155e-01, 6.06138289e-01],\n",
       "       [1.42391510e-02, 7.00285494e-01, 2.85475314e-01],\n",
       "       [2.02333897e-01, 1.80070043e-01, 6.17596090e-01],\n",
       "       [9.82537568e-01, 2.01773737e-03, 1.54446876e-02],\n",
       "       [4.83544081e-01, 7.22209364e-02, 4.44234997e-01],\n",
       "       [1.82776093e-01, 2.08776891e-01, 6.08447015e-01],\n",
       "       [9.85287596e-04, 9.88924682e-01, 1.00899795e-02],\n",
       "       [1.42700281e-02, 6.99984431e-01, 2.85745561e-01],\n",
       "       [2.03174815e-01, 1.79234326e-01, 6.17590845e-01],\n",
       "       [2.04539210e-01, 1.78357974e-01, 6.17102802e-01],\n",
       "       [4.74380940e-01, 4.09808643e-02, 4.84638184e-01],\n",
       "       [4.75971609e-01, 4.06070948e-02, 4.83421355e-01],\n",
       "       [1.42227290e-02, 7.00434208e-01, 2.85343051e-01],\n",
       "       [4.74064201e-01, 4.10547107e-02, 4.84880984e-01],\n",
       "       [9.39849734e-01, 1.93093959e-02, 4.08408046e-02],\n",
       "       [9.40212905e-01, 1.91365406e-02, 4.06505018e-02],\n",
       "       [1.40175847e-02, 7.02302754e-01, 2.83679694e-01],\n",
       "       [1.42240347e-02, 7.00462162e-01, 2.85313845e-01],\n",
       "       [1.42469713e-02, 7.00211644e-01, 2.85541445e-01],\n",
       "       [1.42300408e-02, 7.00363100e-01, 2.85406947e-01],\n",
       "       [9.41110373e-01, 1.89061183e-02, 3.99835519e-02]], dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test = sess.run(p, feed_dict={x:train_x})\n",
    "p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [1, 0, 0]]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
